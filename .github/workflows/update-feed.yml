name: Update Podcast Feed

on:
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch:

jobs:
  update-feed:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install feedparser
        run: pip install feedparser

      - name: Generate fresh feed.xml with error logging
        run: |
          python - <<'EOF'
import feedparser
from xml.etree.ElementTree import Element, SubElement, ElementTree, tostring
from xml.dom import minidom
import datetime
import traceback

try:
    anchor_rss = 'https://anchor.fm/s/10c3f3eac/podcast/rss'
    feed = feedparser.parse(anchor_rss)
    print(f"Successfully parsed Anchor RSS - found {len(feed.entries)} episodes")

    rss = Element('rss', {'version': '2.0'})
    rss.set('xmlns:itunes', 'http://www.itunes.com/dtds/podcast-1.0.dtd')
    rss.set('xmlns:atom', 'http://www.w3.org/2005/Atom')
    channel = SubElement(rss, 'channel')

    # Channel info
    SubElement(channel, 'title').text = 'The Reika Dynasty Public Broadcast'
    SubElement(channel, 'link').text = 'https://grimsythe.github.io/The-Reika-Dynasty-Public-Broadcast/'
    SubElement(channel, 'description').text = 'Stay vigilant. Stay graceful. And pleaseâ€”mind your posture.'
    SubElement(channel, 'language').text = 'en'
    SubElement(channel, 'itunes:author').text = 'Setsumi No Kami'
    SubElement(channel, 'itunes:explicit').text = 'no'
    SubElement(channel, 'itunes:image', {'href': 'https://pbs.twimg.com/profile_images/1995353298837061632/u1DJU9sY.jpg'})

    atom_link = SubElement(channel, 'atom:link')
    atom_link.set('href', 'https://grimsythe.github.io/The-Reika-Dynasty-Public-Broadcast/feed.xml')
    atom_link.set('rel', 'self')
    atom_link.set('type', 'application/rss+xml')

    owner = SubElement(channel, 'itunes:owner')
    SubElement(owner, 'itunes:name').text = 'Alex Waters'
    SubElement(owner, 'itunes:email').text = 'thomas.waters10606@gmail.com'

    for entry in reversed(feed.entries):
        print(f"Processing episode: {entry.title}")
        item = SubElement(channel, 'item')
        SubElement(item, 'title').text = entry.title
        SubElement(item, 'link').text = entry.get('link', 'https://grimsythe.github.io/The-Reika-Dynasty-Public-Broadcast/')

        pub_str = entry.published
        try:
            pub_clean = pub_str.rsplit(' ', 1)[0]  # Strip GMT
            pub_dt = datetime.datetime.strptime(pub_clean, '%a, %d %b %Y %H:%M:%S')
            date_str = pub_dt.strftime('%Y-%m-%d')
        except Exception as e:
            print(f"PubDate parse error for {entry.title}: {e}")
            date_str = '2025-01-01'

        SubElement(item, 'guid', {'isPermaLink': 'false'}).text = f"reika-{date_str}"
        SubElement(item, 'pubDate').text = pub_str

        if entry.enclosures:
            enc = entry.enclosures[0]
            attrs = {'url': enc.href, 'type': enc.type}
            if hasattr(enc, 'length') and enc.length:
                attrs['length'] = enc.length
            SubElement(item, 'enclosure', attrs)

        if hasattr(entry, 'itunes_duration'):
            SubElement(item, 'itunes:duration').text = entry.itunes_duration

        summary = getattr(entry, 'summary', '')
        desc = SubElement(item, 'description')
        desc.text = f"<![CDATA[{summary}]]>"

    # Pretty print fixed
    rough_string = tostring(rss, 'unicode')
    reparsed = minidom.parseString(rough_string)
    pretty_xml = reparsed.toprettyxml(indent="  ")

    with open('feed.xml', 'w', encoding='utf-8') as f:
        f.write(pretty_xml)

    print("SUCCESS: feed.xml created with all episodes!")

except Exception as e:
    print("CRITICAL ERROR:")
    traceback.print_exc()
    raise  # Re-raise to fail the job with logs

EOF

      - name: Commit and push
